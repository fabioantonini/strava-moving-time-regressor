{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871e4c2a",
   "metadata": {},
   "source": [
    "# Strava, Rouvy and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cfa8b7-28bd-4f7f-b6fd-13add5428556",
   "metadata": {},
   "source": [
    "### How to predict 'moving time' on a route by Scikit-Learn\n",
    "<center><img src=\"strava.png\" alt=\"My Account from Strava web page\" /><img src=\"rouvy.png\" alt=\"My Account from Strava web page\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbfc9bf-5348-4f7f-8da4-caf5084634df",
   "metadata": {},
   "source": [
    "I've had a lot of fun riding my bike over the last few years. Unfortunately the Covid pandemic has greatly limited the opportunities for outdoor outings. Plus the winter is harsh in my area. So I subscribed to a nice app called (rouvy.com) and bought an indoor trainer to pedal at home. \n",
    "\n",
    "It was a fantastic experience that continues to this day. Early every day in the morning I can train by pedaling anywhere in the world, tackling the steepest and most legendary climbs. \n",
    "\n",
    "I connected Rouvy to my (free) Strava account so that every route I ride under Rouvy is automatically saved to Strava. After 3 years the end result is that I have more than 500 routes (indoor and outdoor) saved in my Strava account. But how does Machine Learning come into play?\n",
    "\n",
    "When I want to choose the next route to take, I often have only a rough idea of the \"commute time\" it will take. It would be helpful to have some Moving time prediction to better schedule my time. So I decided to use the data available in Strava to train some Machine Learning models and predict the \"commute time\" (also 'Moving time') given some parameters (distance, elevation gain, max grade, average grade...) of the route. This data are available 'a priori' in the Rouvy profile of the route.\n",
    "The notebook, the data and all the pictures are available under my github https://github.com/fabioantonini/strava-moving-time-regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b36bd8-41c6-4725-af1b-60f65ed70194",
   "metadata": {},
   "source": [
    "## Outline\n",
    "Here the topics we are going to talk.\n",
    "\n",
    "- ### Retrieving data from Strava\n",
    "- ### Data Exlporation\n",
    "- ### Data Cleaning\n",
    "- ### Selecting Features and Labels\n",
    "- ### Outliers\n",
    "- ### Save the cleaned data\n",
    "- ### Data Visualization\n",
    "- ### Looking for correlation\n",
    "- ### Avoiding sampling bias\n",
    "- ### Splitting Training and Test sets\n",
    "- ### Linear Regression Model\n",
    "- ### Decision Tree Model\n",
    "- ### Random Forest Model\n",
    "- ### Challenge Gunsan-Saemangeum 2002 prediction\n",
    "- ### Fine-Tune Your Model\n",
    "- ### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b7698-0dac-4eaa-ab98-70204029a99a",
   "metadata": {},
   "source": [
    "## Retrieving data from Strava"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e922a-1fd8-4ca8-9d7d-b0d04ee2df6c",
   "metadata": {},
   "source": [
    "The routes data can be exported by the Strava website from the 'My Account' page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc466d74-b176-4345-a339-f169bd1d460f",
   "metadata": {},
   "source": [
    "<center><img src=\"myaccount.png\" alt=\"My Account from Strava web page\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220f5cc-3560-4943-a5f3-5055490e4939",
   "metadata": {},
   "source": [
    "Search for 'Download or Delete Your Account'. Click on the 'Get Started'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607d464-19f8-4ebc-badd-b9c56172e0a1",
   "metadata": {},
   "source": [
    "<img src=\"export.png\" alt=\"My Account from Strava web page\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae496ad2-fe2d-47de-9000-6d8cddab212c",
   "metadata": {},
   "source": [
    "Click on the 'Request Your Archive' button. As explained, an email will be sent to you with the link to download the zip file containing the data of your Strava activities. Prepare to wait for a while. Strava takes its time to arrange the archive. So you might receive the email after some hours.\n",
    "Anyway in the end you will receive the email and download the zip file (export_31174850.zip for instance).\n",
    "Let's take a look at its content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600a942-cc29-4cc1-bc31-ba4e5f87bb12",
   "metadata": {},
   "source": [
    "<img src=\"zipfile.png\" alt=\"My Account from Strava web page\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e520187-508e-429f-9bef-8a17b3795868",
   "metadata": {},
   "source": [
    "For our purposes only the 'activities.csv' file is required. From the size we can realize that it contains a lot of data. My own 'activities.csv' file has been added to the repo and it will be processed next. Let's import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734532ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression # Regression Model\n",
    "from sklearn.model_selection import train_test_split # to split train and test sets\n",
    "plt.style.use(\"bmh\")\n",
    "%config InlineBackend.figure_formats=[\"png\"]\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv(\"activities.csv\")\n",
    "print(\"dataset type is:\", type(activities), \"length:\", len(activities), \"shape:\", activities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955627ac-41b8-437b-9ee1-947c34256baa",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bdc07",
   "metadata": {},
   "source": [
    "The dataset is made of 855 activities (rows), but unfortunately not all of them are rides by bike.\n",
    "\n",
    "The single route (row) includes 86 columns. Not all the columns contain usable data (many NaN or 'null' are present) because I don't have a full Strava subscription, but only a free account. \n",
    "\n",
    "Let's take a look more in depth to undestand which activities are really useful to our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"columns: \", len(list(activities.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf110f9b-b231-421a-8bf3-3eb34ad36088",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d9681",
   "metadata": {},
   "source": [
    "We need to extract only the columns really useful to train a model.\n",
    "The data appear to be a bit sparsed. Some columns are not valorized at all (because of my free account). Others columns have many 'null' values. We need to identify only the features statistically helpful that are available for each route before riding the route itself.\n",
    "\n",
    "Let's clean the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf11fc",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e998fcb-ee0d-4807-9c8e-21bd068edf2a",
   "metadata": {},
   "source": [
    "In the next section data will be cleaned and filtered to get only routes done by bike (Outdoor and Indoor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbb253",
   "metadata": {},
   "source": [
    "### Getting only activities done by bike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32027cbe-e76e-417b-87fd-78ce8f530fed",
   "metadata": {},
   "source": [
    "We defintely need to get only the activities done by bike. They are labeled as 'Ride' and 'Virtual Ride' in the Strava exported dataset. So we will drop the activities tagged as 'Walk' and 'Run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a13611-c2f0-4a98-9b04-b2d67da15f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities=activities.loc[activities['Activity Type'].isin(['Ride', 'Virtual Ride'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e75fe-bdd5-4fb0-a44d-ea6522c36082",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31573ce-25a6-4f92-b999-978db291a0e2",
   "metadata": {},
   "source": [
    "You can notice that the number of rows decreased a bit. Let's go further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08df08-bed8-4948-b89a-c759948f340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as an alternative you can remove the 'Walk' and 'Run' activities\n",
    "# activities = activities.drop(activities[activities['Activity Type'] == 'Walk'].index)\n",
    "# activities = activities.drop(activities[activities['Activity Type'] == 'Run'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046cad76-cb17-44e5-8b1c-1a3cc13f2101",
   "metadata": {},
   "source": [
    "### Removing short routes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583191c6",
   "metadata": {},
   "source": [
    "When you ride under Rouvy you can optionally have a 'Warm up' and 'Cool down' before and after respectively the selected route. Also these short routes have been recorded under Strava. They are not useful for our purposes. So let's remove all the routes whose 'Moving Time' is less than 3 minutes (180 secs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a02f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities.drop(activities[activities['Moving Time'] < 180].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47fc4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf0c03-450b-4df0-99ed-ef34557d6d89",
   "metadata": {},
   "source": [
    "The count number has decreased again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf328aa-e7f3-46c8-8157-6dbacf2a86fd",
   "metadata": {},
   "source": [
    "### Handling fake data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f4719-1f22-4749-8340-7fa85441ada4",
   "metadata": {},
   "source": [
    "Inspecting the original dataframe we can realize that there are some bad data. For instance it's hard to believe that the 'Max Grade' is 50%. If the min 'Distance' is 0 Km, the route is a 'fake' or the data are corrupted. So these routes can be removed.\n",
    "Let's clean this data by setting a threshold of 25% for the 'Max Grade', and 3 Km's for 'Distance' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852db15-0a71-41a3-9fb8-60c322b91f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities.drop(activities[activities['Max Grade'] > 25].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f3285-7682-4e78-b5c2-b0197b1ff022",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities.drop(activities[activities['Distance'] < 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0deab-e7bf-4c4d-b057-3a0a2d4979e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1286b-f5b1-4364-a34a-898eb3f785df",
   "metadata": {},
   "source": [
    "Now we have 533 bike routes (Indoor and Outdoor). Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f14a1f-52cb-478f-b73b-4d488572496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d64445-5915-4c98-887d-4fddd653b696",
   "metadata": {},
   "source": [
    "Now the data looks better. It's time to get the features really helpful to train our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b57f68-b0a8-4afd-987f-83c497d0d2ed",
   "metadata": {},
   "source": [
    "## Handling 'Null' values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a830f-bd98-4e7a-8cae-f10d1ab91946",
   "metadata": {},
   "source": [
    "We can check the 'null' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9af35-528c-4673-b14a-977370ef447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows_idx = activities.isnull().any(axis=1)\n",
    "activities.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094e100-f6b7-44a6-bfe4-1f7f2b200890",
   "metadata": {},
   "source": [
    "We have a couple of policies to handle the 'Null' values.\n",
    "\n",
    "We can use 'imputation' to set the NaN to the median value of that feature. A more rude approach is to remove the rows with at least one NaN or null value, but in this  case we will lost some data.\n",
    "\n",
    "Let's try to use imputation in order to save the three rows with NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961a1a6-3270-44ef-87f8-7ddb2dac24d3",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ae6e8d-7ac5-4989-ab98-13e56d1c1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = activities[\"Elevation Gain\"].median()\n",
    "activities[\"Elevation Gain\"].fillna(median, inplace=True)  # option 3\n",
    "\n",
    "median = activities[\"Max Grade\"].median()\n",
    "activities[\"Max Grade\"].fillna(median, inplace=True)  # option 3\n",
    "\n",
    "activities.loc[null_rows_idx].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c3788-da03-4cfc-928f-829e89cdb9b6",
   "metadata": {},
   "source": [
    "#### Droping NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd3a6b-01a2-4dea-adcb-87bff428a88d",
   "metadata": {},
   "source": [
    "You can remove the rows with at least one 'null' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3efa664-ecf1-4a62-a776-f91207f24174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if activities.isnull().values.any():\n",
    "#    activities=activities.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd0d563-f9e4-4764-984e-5f422fe09e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bdcc5-5eaa-45e8-8126-3fab4d7b1397",
   "metadata": {},
   "source": [
    "We have 533 records (rows) that can be used to train our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24ebe0-04ae-4891-8d87-416afbcdf483",
   "metadata": {},
   "source": [
    "## Selecting features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da48007-7ee5-4439-83e0-bbe1b2f81c86",
   "metadata": {},
   "source": [
    "After a fast analysis of the available features, only the following features will be used to train the model:\n",
    "- Distance\n",
    "- Elevation gain\n",
    "- Max Grade\n",
    "- Average Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d27ac-d648-48de-81a8-0c71a3b84302",
   "metadata": {},
   "source": [
    "The target label is the 'Moving Time'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc84676-6861-4932-aefa-176d6b60da49",
   "metadata": {},
   "source": [
    "- For sure we expect there is some dependency between the 'Distance' and the 'Moving Time' (the longer the route, the longer it takes to complete it). \n",
    "- Higher is 'Elevation Gain 'of the route (even if the 'Distance' is small), the longer it takes to complete it.\n",
    "- Also the 'Max Grade' is a variable related to the 'Moving Time': a short route with a small 'Evevation Gain' can take a long to time be completed if there are few KM's with a strong climb.\n",
    "- The dataset includes outdoor (recorded from live) routes and indoor routes (recorded by Rouvy). For the outdoor route the 'Average Grade' is close to '0' because I go back home everytime. For indoor routes the 'Average Grade' can be greater than '0' as in the picture here below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604bf4c-e0bf-4492-aa63-83cd23d76096",
   "metadata": {},
   "source": [
    "All these informations can be retrieved by Rouvy, for every available route.\n",
    "Please note that in the picture the Elevation Gain is mapped to the 'Ascended' item.\n",
    "\n",
    "In the next predictions examples we will get the route data from Rouvy and use them to make prediction of the 'Moving Time'. These additional routes are not included in the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3f63a-2a46-431c-9e01-095d47ea33ad",
   "metadata": {},
   "source": [
    "<center><img src=\"rouvy-route.png\" alt=\"Rouvy data for a route\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb598cee-e2cf-42d7-9b4e-99ee730d4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities[[\"Distance\", \"Elevation Gain\", \"Max Grade\", \"Average Grade\", \"Moving Time\"]]\n",
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e4d91-8f86-4cc3-bf36-df2aca962d9f",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8cc79-22ee-4f40-992d-2785cd003e43",
   "metadata": {},
   "source": [
    "Now let's drop some outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad23821-0bc2-4f0c-acb3-1a6ecdeb4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "isolation_forest = IsolationForest(random_state=42)\n",
    "outlier_pred = isolation_forest.fit_predict(activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669de42b-b4d1-45d6-882b-b17b864fcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20545fc4-c59c-4c74-8389-81cff230d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities.iloc[outlier_pred == 1]\n",
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad93548-5e51-4689-846f-12b7ec71b6d9",
   "metadata": {},
   "source": [
    "## Save the cleaned data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f6bdd-a3a9-4eeb-816b-ba49846b4d7f",
   "metadata": {},
   "source": [
    "Now the dataset has been cleaned and filtered. We will develop some models using this data.\n",
    "The dataframe can be stored to the filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b0363-7c8e-430f-b637-d9394fad1892",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.to_csv('cleaned_activities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ecd7b-42d8-4fe6-b647-db5a79222ff0",
   "metadata": {},
   "source": [
    "Let's take a look at the dataframe after the last processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c1191",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c511bb",
   "metadata": {},
   "source": [
    "We can obtain a first impression of the dependency between variables by examining a multidimensional scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c09db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(activities, diagonal=\"kde\", figsize=(12,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6678d93",
   "metadata": {},
   "source": [
    "As expected we can see a linear relationship between the Moving Time and the Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.plot(kind=\"scatter\", x='Distance', y='Moving Time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b657846",
   "metadata": {},
   "source": [
    "there is an approximately linear relationship between Elevation Gain and the Distance: more Kms more the overall gain in altitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadbf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.plot(kind=\"scatter\", x='Distance', y='Elevation Gain', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e7039",
   "metadata": {},
   "source": [
    "We can also generate a 3D plot of the observations, which can sometimes help to interpret the data more easily. Here we plot 'Moving Time' as a function of 'Distance' and 'Elevation Gain'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a99028",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "ax.scatter(activities[\"Distance\"], activities[\"Elevation Gain\"], activities[\"Moving Time\"])\n",
    "ax.set_xlabel(\"Distance\")\n",
    "ax.set_ylabel(\"Elevation Gain\")\n",
    "ax.set_zlabel(\"Moving Time\")\n",
    "ax.set_facecolor(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ab64a-58ae-4ab0-a78c-50e7048a8ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "activities.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b490ee",
   "metadata": {},
   "source": [
    "## Looking for correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826a596",
   "metadata": {},
   "source": [
    "You can easily compute the standard correlation coefficient (also called Pearson's r) between every pair of attributes using the 'corr()' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix= activities.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd4153-342c-4fde-afed-1f33205882d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"Moving Time\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd9aa2-0ade-454a-8054-dc61bf1d36aa",
   "metadata": {},
   "source": [
    "The Moving Time is strongly correlated to the 'Distance' and also to the 'Elevation Gain'. This is asbolutely expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be005775-f153-4bb2-960e-ce4ad429d1f5",
   "metadata": {},
   "source": [
    "We can notice that the 'Max Grade' is weakly correlated to the 'Moving Time'.\n",
    "The 'Average Grade' is not correlated at all. So we decide to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98b1ba-d430-4958-a8fe-d3789ecc4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.drop('Average Grade', inplace=True, axis=1)\n",
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437cc739-1402-42c1-bfb6-6903c107003a",
   "metadata": {},
   "source": [
    "## Avoiding sampling bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65839252-2482-4930-a781-2fe57efd9459",
   "metadata": {},
   "source": [
    "Before splitting the dataset into a Training and a Test set we need to face the problem of 'Sampling bias'. Usually we can use a random sampling approach. This is generally fine if your dataset is large enough (especially relative to the number of attributes), but if it is not, you run the risk of introducing a significant sampling bias. In our case the dataset is quite small. The risk to face sampling bias is high. We need a workaround.\n",
    "\n",
    "From the previous histograms we can notice that most 'Distance' values are clustered around 10 to 15 Km's, but some 'Distance's go far beyond 70. It is important to have a sufficient number of instances in your dataset for each stratum, or else the estimate of the stratum’s importance may be biased. This means that you should not have too many strata, and each stratum should be large enough. The following code uses the \n",
    "pd.cut() function to create an income category attribute with 4 categories (labeled\n",
    "from 1 to 4): category 1 ranges from 0 to 20 (i.e., less than 20 Km's), category 2 from\n",
    "20 to 40 Km's, and so on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82e150-26ed-46b3-aa23-629ba3b429fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities[\"Distance_cat\"] = pd.cut(activities[\"Distance\"],\n",
    " bins=[0, 20, 40, 60, np.inf],\n",
    " labels=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936ec61-d358-470a-8c10-ff3e0b73f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities[\"Distance_cat\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aeb659-cd2a-4f22-9a0e-705d600aaa41",
   "metadata": {},
   "source": [
    "Now you are ready to do stratified sampling based on the income category. For this\n",
    "you can use Scikit-Learn’s StratifiedShuffleSplit class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79106bae-57e6-4f04-9630-af3f2e625274",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4933c-39f4-40c9-a797-007ff1931d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.pop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c01a984-726f-4ec5-9842-871ecc66de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554f98c-2fb9-4994-ae4b-76bed06b4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f170d6-d280-4447-9930-e5fb3d7f5054",
   "metadata": {},
   "source": [
    "## Splitting Training and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a2833-28a5-415c-b111-83865c4183f6",
   "metadata": {},
   "source": [
    "Now it's time to get our Training and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369bfae-475b-4960-99ca-b330c9020d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=random_state)\n",
    "strat_splits = []\n",
    "for train_index, test_index in splitter.split(activities, activities[\"Distance_cat\"]):\n",
    "    strat_train_set_n = activities.iloc[train_index]\n",
    "    strat_test_set_n = activities.iloc[test_index]\n",
    "    strat_splits.append([strat_train_set_n, strat_test_set_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a820ed36-57cf-49e5-846d-7a8f14bf916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(strat_splits))\n",
    "strat_train_set, strat_test_set = strat_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c542d1-78cb-43e1-adc0-70d66db32250",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f0676-17af-42eb-b876-53d30d88b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbf0bd-208d-45f4-a973-cfa52c071dfb",
   "metadata": {},
   "source": [
    "It's much shorter to get a single stratified split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0b602-57a4-4ad7-9c0c-85e63041294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set, strat_test_set = train_test_split(\n",
    "    activities, test_size=0.2, stratify=activities[\"Distance_cat\"], random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dad606-023b-4206-b4ce-af2f6e236f57",
   "metadata": {},
   "source": [
    "Let's extract the labels for the Training and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec91bd9-defd-4521-8493-abc273b045ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set_labels=strat_train_set.pop(\"Moving Time\")\n",
    "print(type(strat_train_set_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1effe7-ffbb-407a-8b9c-fe13fe98d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set_labels=strat_test_set.pop(\"Moving Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc035d6-488b-47cb-841f-779b57305e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255608d-7752-4c48-a4ed-63d31403c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4f7f9-9609-499e-9962-fd79c92a4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b78b38-198e-4556-a598-2d07435e69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defb9b3-c85c-4e73-9d3c-e3e49a0195d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"Distance_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167d6b0-a50a-4e42-9aa3-d8a861f8fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_cat_proportions(data):\n",
    "    return data[\"Distance_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(activities, test_size=0.2, random_state=random_state)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall %\": distance_cat_proportions(activities),\n",
    "    \"Stratified %\": distance_cat_proportions(strat_test_set),\n",
    "    \"Random %\": distance_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props.index.name = \"Distance Category\"\n",
    "compare_props[\"Strat. Error %\"] = (compare_props[\"Stratified %\"] /\n",
    "                                   compare_props[\"Overall %\"] - 1)\n",
    "compare_props[\"Rand. Error %\"] = (compare_props[\"Random %\"] /\n",
    "                                  compare_props[\"Overall %\"] - 1)\n",
    "(compare_props * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62e90f-2ea6-49d2-bfb3-37a0b0b225ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"Distance_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d99f06-4c2a-4644-bae3-6cefba93c8cb",
   "metadata": {},
   "source": [
    "Now we have a cleaned Training and Test sets. For the time being put aside the Test set and let's work only on the Training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42409e5e-b465-4d86-91d2-2a7619609b02",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ae997-dc6d-40b2-bcb2-d682c2757f66",
   "metadata": {},
   "source": [
    "One of the most important transformations you need to apply to your data is feature\n",
    "scaling. With few exceptions, Machine Learning algorithms don’t perform well when\n",
    "the input numerical attributes have very different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1779c-600b-4a69-8edb-896b50b51d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "strat_train_set_norm = pd.DataFrame(scaler.fit_transform(strat_train_set), columns = strat_train_set.columns)\n",
    "strat_train_set_norm.describe()\n",
    "print(\"scaler mean {}\".format(scaler.mean_))\n",
    "\n",
    "test_scaler = StandardScaler()\n",
    "strat_test_set_norm = pd.DataFrame(test_scaler.fit_transform(strat_test_set), columns = strat_test_set.columns)\n",
    "strat_test_set_norm.describe()\n",
    "print(\"test scaler mean {}\".format(test_scaler.mean_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58610531-c393-4a3c-91c7-9f68b31381da",
   "metadata": {},
   "source": [
    "## Evaluation, prediction and printing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55179109-2cfa-4f5a-9bd3-cf96e2ce89db",
   "metadata": {},
   "source": [
    "Before diving into the models training let's prepare a toolbox of functions that will come back to help to execute the prediction and the evaluation of a generic model. This will be helpful to collect the accuracy of each model in a dictionary and compare them later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c2c45-2553-478f-a761-0e71436d7ee9",
   "metadata": {},
   "source": [
    "Let's define a dictionary to collect the model's data (model handler, cross validation scores, rmse...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756db98b-811f-4c2a-ac20-0c22bc40da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "evaluations = {}\n",
    "models = {}\n",
    "class model_instance:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.name = type(model).__name__\n",
    "        self.scores = None\n",
    "        self.cross_val_score = 0\n",
    "        self.training = {\"accuracy\": 0, \"rmse\": 0}\n",
    "        self.test = {\"accuracy\": 0, \"rmse\": 0}\n",
    "        self.cross_val_score = []\n",
    "        self.cross_val_score_rms = []\n",
    "        \n",
    "    def prediction(self, moving_time, data):\n",
    "        predicted_moving_time = self.model.predict(data)\n",
    "        error = abs(100*(predicted_moving_time-moving_time)/moving_time)\n",
    "        return predicted_moving_time, error\n",
    "    \n",
    "    def accuracy(self, dataset_name, dataset, dataset_labels):\n",
    "        dataset_predictions = self.model.predict(dataset)\n",
    "        if dataset_name == \"training\":\n",
    "            self.training['accuracy'] = self.model.score(dataset, dataset_labels)\n",
    "        elif dataset_name == \"test\":\n",
    "            self.test['accuracy'] = self.model.score(dataset, dataset_labels)\n",
    "\n",
    "    def rmse(self, dataset_name, dataset, dataset_labels):\n",
    "        dataset_predictions = self.model.predict(dataset)\n",
    "        if dataset_name == \"training\":\n",
    "            self.training['rmse'] = np.sqrt(mean_squared_error(dataset_labels, dataset_predictions))\n",
    "        elif dataset_name == \"test\":\n",
    "            self.test['rmse'] = np.sqrt(mean_squared_error(dataset_labels, dataset_predictions))\n",
    "\n",
    "    def print_model_accuracy(self, dataset_name):\n",
    "        if dataset_name == \"training\":\n",
    "            print(\"Model {}: Accuracy on {} set:{}\".format(self.name, dataset_name, self.training['accuracy']))\n",
    "        elif dataset_name == \"test\":\n",
    "            print(\"Model {}: Accuracy on {} set:{}\".format(self.name, dataset_name, self.test['accuracy']))\n",
    "            \n",
    "    def print_model_rmse(self, dataset_name):\n",
    "        if dataset_name == \"training\":\n",
    "            print(\"Model {}: Rmse on {} set:{}\".format(self.name, dataset_name, self.training['rmse']))\n",
    "        elif dataset_name == \"test\":\n",
    "            print(\"Model {}: Rmse on {} set:{}\".format(self.name, dataset_name, self.test['rmse']))\n",
    "\n",
    "    def cross_val_score_eval(self, dataset, dataset_labels):\n",
    "        self.cross_val_score = cross_val_score(self.model, dataset, dataset_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "        self.cross_val_score_rmse = np.sqrt(-self.cross_val_score)\n",
    "        \n",
    "    def print_model_cross_val_score(self):\n",
    "        print(\"Cross Val Score {}\".format(self.cross_val_score))\n",
    "        print(\"Cross Val Rmse {}\".format(self.cross_val_score_rmse))\n",
    "        print(\"Mean:\", self.cross_val_score_rmse.mean())\n",
    "        print(\"Standard deviation:\", self.cross_val_score_rmse.std())\n",
    "        \n",
    "    def plot_learning_curves(self, X, y):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "        train_errors, val_errors = [], []\n",
    "        for m in range(50, len(X_train)):\n",
    "            self.model.fit(X_train[:m], y_train[:m])\n",
    "            y_train_predict = self.model.predict(X_train[:m])\n",
    "            y_val_predict = self.model.predict(X_val)\n",
    "            train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
    "            val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
    "        plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
    "        plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6076e9e5-4ce4-453b-99a8-0b17c6de0f1f",
   "metadata": {},
   "source": [
    "### Better Evaluation Using Cross-Validation\n",
    "One way to evaluate a model would be to use the train_test_split function to split the training set into a smaller training set and a validation set, then train your models against the smaller training set and evaluate them against the validation set. It’s a bit of work, but nothing too difficult and it would work fairly well.\n",
    "\n",
    "A great alternative is to use Scikit-Learn’s K-fold cross-validation feature. The code of the method 'cross_val_score_eval' randomly splits the training set into 10 distinct subsets called folds, then it trains and evaluates the model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores. This approach will be used to evaluate each model on the Training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7b3e52-8918-4576-b748-f7d3977eb2d9",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447c4cf-3cd7-463e-9f5a-a8d3422654f1",
   "metadata": {},
   "source": [
    "We will created a fitted linear model using the formula API of the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b14863",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg = LinearRegression()\n",
    "linear_reg_name = type(linear_reg).__name__\n",
    "models[linear_reg_name] = model_instance(linear_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946d8a5-822c-4712-949b-0c634256df56",
   "metadata": {},
   "source": [
    "Let's train the Linear Regressor model on the stratified features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b97e1-c3bb-46fa-b31f-a6a19051eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564fef7",
   "metadata": {},
   "source": [
    "### Linear Regressor Parameters \n",
    "The $\\mathbf{w}$ and $\\mathbf{b}$ parameters are referred to as 'coefficients' and 'intercept' in scikit-learn. In other term the model function can be written as $f_{w,b}(\\vec{x})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715acca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = models[linear_reg_name].model.intercept_\n",
    "w = models[linear_reg_name].model.coef_\n",
    "print(f\"w = {w:}, b = {b:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a9e49-bf8e-4e77-99f6-540648eb2cc2",
   "metadata": {},
   "source": [
    "### Accuracy and  Root Mean squared error of the LinearRegressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f539b00",
   "metadata": {},
   "source": [
    "Let’s measure the regression model’s RMSE on the whole training set using the preiously defined function 'evaluation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332dca5f-c76b-44eb-84a7-01184a26a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[linear_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[linear_reg_name].cross_val_score_eval(strat_train_set, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026322dc-8699-4143-8621-7453b86ea50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883a17a-b256-4dde-9025-6a0b84d20e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581617c3-2c2a-425b-ac84-80a05ad04f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df7ae7-32b5-4124-9844-bf0ad7f23fde",
   "metadata": {},
   "source": [
    "### Learning Curves of the Linear Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28926b6c-cc6f-4a15-97d1-27ae1629ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[linear_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10340639-8183-4099-8616-767b3673414b",
   "metadata": {},
   "source": [
    "## Ridge Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0051d12-ab39-4c7d-8707-fa621bc32976",
   "metadata": {},
   "source": [
    "Ridge Regression (also called Tikhonov regularization) is a regularized version of Lin‐\n",
    "ear Regression: a regularization term is added to the cost function. This forces the learning algorithm to not only fit the data but also keep the model weights as small as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776d416-fb50-4d9c-b3bf-83247659ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg_name = type(ridge_reg).__name__\n",
    "models[ridge_reg_name] = model_instance(ridge_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26482031-2e73-4b27-bebf-f809a9417f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd90a0b-5b87-4633-91c1-8fa890cff766",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the Ridge Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e92ac4-d06c-4b67-b2f1-9f3afc34cb67",
   "metadata": {},
   "source": [
    "Let's evauluate the Accuracy and RMSE of the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0793458-997a-417d-8260-f5a1859cccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[ridge_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[ridge_reg_name].cross_val_score_eval(strat_train_set, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d4078-d6e2-4ef9-8862-8bc4b9c0ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38641fa-57bf-4029-80c0-f3eaffcf1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0353f6-211a-48e4-a54b-a66a423d58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f8a18-2006-4d9f-8c7a-5fa853351ec8",
   "metadata": {},
   "source": [
    "### Learning Curves for the Ridge Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9c1b1-f3ca-49be-b4e0-8137a940f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[ridge_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44501827-ccd6-47d2-90a5-c7118d9ef7c5",
   "metadata": {},
   "source": [
    "## Decision tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e194e0-72a4-45fb-a385-635b2a11fd91",
   "metadata": {},
   "source": [
    "In order to try to improve the accuracy on the Training set let's try a different model able to catch nonlinear patterns in the data.\n",
    "Let’s train a DecisionTreeRegressor. This is a powerful model, capable of finding complex nonlinear relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0e52c-cd4c-4cac-b4b0-0a9b7ab31c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg_name = type(tree_reg).__name__\n",
    "models[tree_reg_name] = model_instance(tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb11859-df60-4e72-9f86-ec78d37462d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeccbc7-4f80-4dc5-9e47-99b8e01f64c6",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f22eaf-4c8d-489b-839c-f19e237d8ca9",
   "metadata": {},
   "source": [
    "Let's evauluate the Accuracy and RMSE of the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bd696-93f4-4ba9-9c03-46312b0c646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[tree_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[tree_reg_name].cross_val_score_eval(strat_train_set, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68f385-27fc-415c-a3b3-23f2d6f90717",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2b1f-b845-4547-b4d1-dc0b7ba09a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b3202-f646-4488-8d2f-e3cffb0fb4a4",
   "metadata": {},
   "source": [
    "Not error at all on the Training data? At a first glance the Model seems to be perfect.\n",
    "Of course, it is much more likely that the model has badly overfit the data. How can you be sure?\n",
    "We'll use part of the training set for training, and part for model validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbaf24f-a160-4573-a6b9-6a7fdd8c87bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47d036-b91b-4ead-996f-7a1a3592d027",
   "metadata": {},
   "source": [
    "Now the real nature of the Decision Tree has come to light. The mean RMSE is about 1500 secs and the Standard Deviation is around 470 secs. This is not so far from the Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c097a-66aa-49d2-b2f4-9056c91b39a4",
   "metadata": {},
   "source": [
    "The Decision Tree model is overfitting so badly that it performs worse than the Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f10ebf-91e8-4cc1-a0fc-37a689236cca",
   "metadata": {},
   "source": [
    "### Learning Curves for the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099459e-2437-40dd-9dd1-3a72be11355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[tree_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb37ac-d7d1-4a0a-ae24-79bf2345ce19",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad635a5-750e-411f-9f1a-b42895c2dddd",
   "metadata": {},
   "source": [
    "Let’s try one last model now: the RandomForestRegressor. Random Forests work by training many Decision Trees on random subsets of the features, then averaging out their predictions. Building a model on top of many other models is called Ensemble Learning, and it is often a great way to push ML algorithms even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebadb4-213b-4261-bfc9-c056d76908f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg_name = type(forest_reg).__name__\n",
    "models[forest_reg_name] = model_instance(forest_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d1248-31f6-4caf-91dd-2b24f96af89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d044a73-44d4-4d76-ab67-4cf260c95d3f",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d4a68-84a7-4832-b564-7fca8fd0f772",
   "metadata": {},
   "source": [
    "Let's evauluate the Accuracy and RMSE of the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd0331-916d-460c-8f3e-0e106201eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[forest_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[forest_reg_name].cross_val_score_eval(strat_train_set, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8fa1c-722e-4634-b272-d092df9d5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbad227-c1c0-48f0-bbcd-264cfb91f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f30ece3-e177-4644-b1d6-836a241a4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23ed85-da32-4b81-9cff-cb66e081ab07",
   "metadata": {},
   "source": [
    "Now it sounds better and more reasonable. The Standard Deviation decreased a bit if compared to the Decision Tree Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9477f753-a3a8-4918-a6c4-0122347f653b",
   "metadata": {},
   "source": [
    "### Learning Curves for the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f113b14-55d6-40d3-9ac8-25e76eff90f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[forest_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b555edb3-6d69-41f3-b08e-294dfe9f5211",
   "metadata": {},
   "source": [
    "## Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a83cdb-2b56-45a6-9717-0cae2a3fb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "degree=2\n",
    "poly_reg=make_pipeline(PolynomialFeatures(degree),LinearRegression())\n",
    "\n",
    "poly_reg_name = type(poly_reg).__name__\n",
    "models[poly_reg_name] = model_instance(poly_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809309f9-b1d0-45c8-a64d-f95c0a71ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbfc791-ef80-4083-9079-ed04cdbf24c1",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the Polynomial Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ba0347-2126-495f-b4c5-12fd66d28eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[poly_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels)\n",
    "models[poly_reg_name].cross_val_score_eval(strat_train_set, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4524032-245e-48d1-bd47-fac2b10eeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b63d4-c762-4c1b-9d05-797652a16f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece05151-2e0b-42ee-bc02-116f28fc12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962b7c8-8cbb-4270-b9bf-1570812501f5",
   "metadata": {},
   "source": [
    "### Learning Curves for the Polynomial Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19f770-6720-4b92-92fb-d2b29ee2cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[poly_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9102859-2e83-4f1e-aac6-5cd601eea24b",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f02df1-9c4e-4b15-8abc-6e396f974463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=1000, penalty=\"l2\")\n",
    "sgdr_reg_name = type(sgd_reg).__name__\n",
    "models[sgdr_reg_name] = model_instance(sgd_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c65eb-6369-42f8-beee-602f5680368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels)\n",
    "print(f\"number of iterations completed: {models[sgdr_reg_name].model.n_iter_}, number of weight updates: {models[sgdr_reg_name].model.t_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c9f44-f2fe-4fee-9b25-fe0dbc2da443",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the SGD Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e913a-c869-413e-a711-1b296ab401c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[sgdr_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[sgdr_reg_name].cross_val_score_eval(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006735b4-4381-4b59-81df-2d30dea629aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28403d4-94b2-4c06-be4f-57ffd54376d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757c043-e9f3-4ff6-bfc2-e3a17f6a3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f54089-cf44-4c62-b7f4-6ab5c82c56c0",
   "metadata": {},
   "source": [
    "### Learning Curves for the SGD Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac478535-4ef7-4819-8215-bbc649c94a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[sgdr_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47651ba0-3c57-4559-a608-87c46e2e4b05",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e618d28-0ffb-4b1c-9d60-5148e676e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "#svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg = SVR(kernel=\"poly\", degree=3, C=100, epsilon=0.01)\n",
    "svm_reg_name = type(svm_reg).__name__\n",
    "models[svm_reg_name] = model_instance(svm_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9f1e7-1b5c-4695-8f6d-0d19794c8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].model.fit(strat_train_set_norm, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca888b-4447-425b-9de8-bac0face17f4",
   "metadata": {},
   "source": [
    "### Mean squared error and Accuracy of the SVM Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2b0bf-3b85-4fa7-aa9f-43def5a441ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].accuracy(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[svm_reg_name].rmse(\"training\", strat_train_set_norm, strat_train_set_labels.ravel())\n",
    "models[svm_reg_name].cross_val_score_eval(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8437f-16db-4d50-809c-73cb1559d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].print_model_accuracy('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc9c7e2-5e89-41b3-8935-b98f4a4130e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].print_model_rmse('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a314a-9217-4a5e-a5ca-edb89d49c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].print_model_cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2f4ae-ac3d-4682-ad96-3e946a28e8cb",
   "metadata": {},
   "source": [
    "### Learning Curves for the SVM Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3feb4-e2f9-44f4-9a22-3c554eeff142",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[svm_reg_name].plot_learning_curves(strat_train_set_norm, strat_train_set_labels.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c5282-9ea0-411a-ad89-829f6542c1d9",
   "metadata": {},
   "source": [
    "## Performance on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3632e33-794a-4c64-85c9-d0e1cd6f91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    models[model].accuracy(\"test\", strat_test_set_norm, strat_test_set_labels.ravel())\n",
    "    models[model].rmse(\"test\", strat_test_set_norm, strat_test_set_labels.ravel())\n",
    "    models[model].print_model_accuracy('test')\n",
    "    models[model].print_model_rmse('test')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adb241-1f73-4dc1-9b9e-0bdd06609a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracies = []\n",
    "test_accuracies = []\n",
    "model_names = []\n",
    "for model in models.keys():\n",
    "    training_accuracies.append(models[model].training['accuracy'])\n",
    "    test_accuracies.append(models[model].test['accuracy'])\n",
    "    model_names.append(models[model].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17453b21-7691-4fb8-b334-73d70c8ec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_names, training_accuracies, \"r+\", linewidth=2, label=\"train\")\n",
    "plt.plot(test_accuracies, \"b+\", linewidth=2, label=\"test\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend(framealpha=1, frameon=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a33d0c-cc5b-4cdd-b002-e345939372f5",
   "metadata": {},
   "source": [
    "## Challenge Gunsan-Saemangeum 2002 prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1c399-4c30-4919-9d00-861820bd1dfc",
   "metadata": {},
   "source": [
    "Let's try to predict the Moving Time of a new route I rode the last weew, the Challenge Gunsan-Saemangeum 2022.\n",
    "\n",
    "The input data are:\n",
    "- Distance: 30 Km's\n",
    "- Elevation Gain: 26\n",
    "- Max Grade: 3%\n",
    "\n",
    "The real Moving Time is 53 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc950f9-4396-488a-8f1d-afa6c8dcb4eb",
   "metadata": {},
   "source": [
    "<center><img src=\"gunsam.png\" alt=\"Challenge Gunsan-Saemangeum 2022 - Rouvy\" /><img src=\"test-route.png\" alt=\"Challenge Gunsan-Saemangeum 2022 - Strava\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d567953-c451-457f-8598-14351867d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunsan_real_moving_time=53*60 # secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6eaf77-02d9-4f5a-93b8-e8e4f4991403",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunsan_route_data = pd.DataFrame([[29.99, 26, 3]], columns = strat_train_set.columns)\n",
    "#print(scaler.mean_)\n",
    "#gunsan_route_data = [[29.99, 26, 3]]\n",
    "gunsan_route_data_norm = test_scaler.transform(gunsan_route_data) #gunsan_route_data.reshape(1,-1)\n",
    "#print(type(gunsan_route_data_norm))\n",
    "#print((gunsan_route_data_norm))\n",
    "gunsan_route_data_norm_df = pd.DataFrame(gunsan_route_data_norm, columns = strat_train_set.columns)\n",
    "#print(type(gunsan_route_data_norm_df))\n",
    "#print((gunsan_route_data_norm_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044a1d6-c132-40e3-8ba2-f4524a34fc93",
   "metadata": {},
   "source": [
    "### Model's prediction comparison on the new route"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cd254-560e-40ac-9c56-81014abad6be",
   "metadata": {},
   "source": [
    "Let's print out the predictions of the three models trained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa0ebb-3e62-4402-ae9c-225b6357b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.keys():\n",
    "    predicted_moving_time, error = models[model].prediction(gunsan_real_moving_time, gunsan_route_data_norm_df)\n",
    "    print(\"Model {}: Moving time {} mins, error {} %:\".format(models[model].name, predicted_moving_time/60, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b76d4-d125-4fdf-ab53-d7dd50960f75",
   "metadata": {},
   "source": [
    "##  (Brunnen) - Tour de Suisse 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05085f47-9e03-42cc-97d6-4ce74e054053",
   "metadata": {},
   "source": [
    "Let's try another route. The input data are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd721487-5524-45d9-8da1-4b043a4c45ed",
   "metadata": {},
   "source": [
    "The input data are:\n",
    "\n",
    "- Distance: 27.7 Km's\n",
    "- Elevation Gain: 467\n",
    "- Max Grade: 13%\n",
    "\n",
    "The real Moving Time is 1:03:52 = 3832 secs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402e9e4-adc8-4cc5-adaa-58e69b2600f0",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"brunnen-rouvy.png\" alt=\"Stage 4 (Brunnen) - Tour de Suisse 2022 - Rouvy\" />\n",
    "<img src=\"brunnen-strava.png\" alt=\"Stage 4 (Brunnen) - Tour de Suisse 2022 - Strava\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f7534-6eec-4245-9802-6fa6e0c6d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "brunnen_real_moving_time=3600 + 3*60 + 52 # secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c042056-6c42-40f7-94c8-a84e8119a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scaler.mean_)\n",
    "brunnen_route_data = pd.DataFrame([[27.87, 467, 13]], columns = strat_train_set.columns)\n",
    "#brunnen_route_data = [[27.87, 467, 13]]\n",
    "brunnen_route_data_norm = test_scaler.transform(brunnen_route_data)\n",
    "#print(type(brunnen_route_data_norm))\n",
    "#print((brunnen_route_data_norm))\n",
    "brunnen_route_data_norm_df = pd.DataFrame(brunnen_route_data_norm, columns = strat_train_set.columns)\n",
    "#print(typebrunnen_route_data_norm_df))\n",
    "#print((brunnen_route_data_norm_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c351a6-0887-482b-86bd-309bda314427",
   "metadata": {},
   "source": [
    "### Model's prediction comparison for the \"Brunnen\" route"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebd8f4-fe41-4f6b-ae17-4899a386d671",
   "metadata": {},
   "source": [
    "Let's print out the predictions of the models trained so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff968f6-ad68-431f-be2b-23a6f916f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_moving_times = []\n",
    "errors = []\n",
    "for model in models.keys():\n",
    "    predicted_moving_time, error = models[model].prediction(brunnen_real_moving_time, brunnen_route_data_norm_df)\n",
    "    print(\"Model {}: Moving time {} mins, error {} %:\".format(models[model].name, predicted_moving_time/60, error))\n",
    "    predicted_moving_times.append(predicted_moving_time)\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77999c09-c6d0-4320-9ee3-0817027e5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_names, errors, \"r+\", linewidth=2, label=\"Predicted Moving Time\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.legend(framealpha=1, frameon=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4313c-c7f5-45cc-9a90-63de86fb8670",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8b377-ad77-4f7a-8775-2b0c53c9655e",
   "metadata": {},
   "source": [
    "The purpose of this exercise was to to develop a Machine Learning Model to predict the 'Moving Time' of a Route based on Rouvy data. Here below a recap of what has been done\n",
    "\n",
    "- Data includes more of 500 'outdoor' and 'indoor' routes \n",
    "- The 'indoor' routes have been exported by Rouvy to Strava\n",
    "- The 'outdoor' routes have been recorded directly by Strava\n",
    "- The data have been cleaned and prepared for training\n",
    "- The dataset has been splitted into a 'Training' and 'Test' sets\n",
    "- A bunch of Regressor Models have been trained on the 'Training' set.\n",
    "- Each model has been validated by cross validation score and accuracy\n",
    "- For each model the Learning curves have been plotted for 'Training' and 'Test' sets\n",
    "- Decision Tree model overfit badly the 'Training' set.\n",
    "- LinearRegressor, Ridge, RandomForest, Pipeline and SGDRegressor models have a performance of 90% (more or less).\n",
    "- The Polynomial Regressor (Pipeline) showed the highest accuracy on the 'Test' set.\n",
    "- On the two sample routes the best 'Moving Time' has been predicted by the Polynomial, SVR and SGD models\n",
    "- In order to improve the performance of the models more data are required\n",
    "- As a possible follow up, an Ensemble model including the most promising models can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd19ecd-27e9-42fb-acee-b2fb24f4ac85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d24ede-96bb-48af-8256-6dd161ea4b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9358880f-ecb6-4634-a498-107e436d9c81",
   "metadata": {},
   "source": [
    "## Fine-Tune Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aadb08d-f689-47af-a209-f42b56ebb789",
   "metadata": {},
   "source": [
    " You now need to fine-tune the Random Forest. Let’s look at a few ways you can do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1d7f9-434d-48d8-9eb9-0687eb625742",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ffd9cc-71cb-46ad-8157-473de6307bd5",
   "metadata": {},
   "source": [
    "One way to do that would be to fiddle with the hyperparameters manually, until you\n",
    "find a great combination of hyperparameter values. This would be very tedious work,\n",
    "and you may not have time to explore many combinations. \n",
    "Instead you should get Scikit-Learn’s GridSearchCV to search for you. All you need to\n",
    "do is tell it which hyperparameters you want it to experiment with, and what values to\n",
    "try out, and it will evaluate all the possible combinations of hyperparameter values,\n",
    "using cross-validation. For example, the following code searches for the best combi‐\n",
    "nation of hyperparameter values for the RandomForestRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311de6af-aa8d-44a7-9dfa-0295fac373ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    " {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    " {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51290e10-62b5-4266-9d10-7fd4b21971c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(models[forest_reg_name].model, param_grid, cv=10,  scoring='neg_mean_squared_error', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(strat_train_set_norm, strat_train_set_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5204f2b-0953-4d74-a0ee-3ef1a2d67c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09061d0b-dc2a-48c8-a77a-24453bb478db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8dab5-7ce1-4f20-b7fb-19df9313ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0257f7d-e8cb-4412-a8ae-85c58c49c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c022bad-738d-46fc-8c69-903629e92f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_forest = grid_search.best_estimator_\n",
    "best_random_forest_name = \"BestRandomForest\"\n",
    "models[best_random_forest_name] = model_instance(best_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c009a-5225-4b36-9a7a-8ce4dbd33bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_random_forest_name].accuracy(\"test\", strat_test_set_norm, strat_test_set_labels)\n",
    "models[best_random_forest_name].rmse(\"test\", strat_test_set_norm, strat_test_set_labels)\n",
    "models[best_random_forest_name].print_model_accuracy('test')\n",
    "models[best_random_forest_name].print_model_rmse('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb42ddc-a67a-47e3-801a-97b76e3823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_moving_time, error = models[best_random_forest_name].prediction(gunsan_real_moving_time, gunsan_route_data_norm_df)\n",
    "print(\"Model {}: Moving time {} mins, error {} %:\".format(models[best_random_forest_name].name, predicted_moving_time/60, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b4b24-0c0d-479d-a758-b7dd2ed86d29",
   "metadata": {},
   "source": [
    "### Learning curves of the best Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f30196-b547-4142-a6e8-cb7f7d13b596",
   "metadata": {},
   "source": [
    "Let’s look at the learning curves of the plain Best Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461c379a-56f7-4744-aef0-14a60bb0b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[best_random_forest_name].plot_learning_curves(strat_train_set, strat_train_set_labels.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
